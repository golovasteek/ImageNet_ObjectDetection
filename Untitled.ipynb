{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROJECT_DIR = \"/home/enick/Kaggle/ImageNet/ObjectDetection\"\n",
    "if PROJECT_DIR not in sys.path:\n",
    "    sys.path.append(PROJECT_DIR)\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tools import reader\n",
    "from models import preprocess\n",
    "from models import semi_alexnet_v1\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [8., 8.]\n",
    "DATASET_SIZE = 349319\n",
    "FILE = \"./preprecessed_data/one_biggest_{}.csv\".format(DATASET_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(FILE):\n",
    "    print FILE, \"exists skipping creation\"\n",
    "else:\n",
    "    with open(FILE, \"w\") as f:\n",
    "        f.write(\",Image,class_id,class_name\\n\")\n",
    "        f.writelines(\n",
    "            \"{},{},{},{}\\n\".format(i, item[0], item[1], item[2])\n",
    "            for i, item in itertools.izip(tqdm_notebook(range(DATASET_SIZE)), reader.list_file_class()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: 201\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(FILE, index_col=0)\n",
    "LABELS = data.class_id.nunique()\n",
    "print \"Labels:\", LABELS\n",
    "\n",
    "LABELS_MAP = dict((name, (num, reader.get_desc(name)))\n",
    "    for num, name in enumerate(data.class_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_valid = train_test_split(data, test_size=0.2)\n",
    "test_data, valid_data = train_test_split(test_valid, test_size=0.5)\n",
    "\n",
    "train_data.to_csv(\"./preprecessed_data/one_biggest_{}_train.csv\".format(DATASET_SIZE))\n",
    "valid_data.to_csv(\"./preprecessed_data/one_biggest_{}_valid.csv\".format(DATASET_SIZE))\n",
    "test_data.to_csv(\"./preprecessed_data/one_biggest_{}_test.csv\".format(DATASET_SIZE))\n",
    "with open(\"./preprecessed_data/one_biggest_labels.csv\".format(DATASET_SIZE), \"w\") as f:\n",
    "    json.dump(LABELS_MAP, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./preprecessed_data/one_biggest_{}_train.csv\".format(DATASET_SIZE))\n",
    "valid_data = pd.read_csv(\"./preprecessed_data/one_biggest_{}_valid.csv\".format(DATASET_SIZE))\n",
    "#test_data = pd.read_csv(\"./preprecessed_data/one_biggest_{}_test.csv\".format(DATASET_SIZE))\n",
    "\n",
    "with open(\"./preprecessed_data/one_biggest_labels.csv\".format(DATASET_SIZE), \"r\") as f:\n",
    "    LABELS_MAP = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_one_hot(class_id):\n",
    "    one_hot = np.zeros(len(LABELS_MAP))\n",
    "    one_hot[LABELS_MAP[class_id][0]] = 1.\n",
    "    return pd.Series(one_hot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataset_from_data(data, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (data.Image.as_matrix(), data.class_id.apply(preprocess_one_hot).as_matrix()))\n",
    "    dataset = dataset.map(preprocess.input_parser)\n",
    "    dataset = dataset.prefetch(batch_size * 2)\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 3)\n",
      "(?, ?, 3)\n",
      "[None, 118, 102, 48]\n",
      "[None, 55, 47, 128]\n",
      "[None, 27, 23, 192]\n",
      "[None, 27, 23, 192]\n",
      "[None, 27, 23, 128]\n",
      "[-1, 79488]\n",
      "[None, 2048]\n",
      "[None, 2048]\n",
      "One hot: [None, 201]\n",
      "[None]\n",
      "[None]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 20\n",
    "EPOCHS = 10\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    train_dataset = dataset_from_data(train_data, BATCH_SIZE)\n",
    "    valid_dataset = dataset_from_data(valid_data, BATCH_SIZE)\n",
    "    \n",
    "    iterator = tf.data.Iterator.from_structure(\n",
    "        train_dataset.output_types,\n",
    "        train_dataset.output_shapes\n",
    "        )\n",
    "    \n",
    "    images, onehot_labels = iterator.get_next()\n",
    "\n",
    "    train_initialize_op = iterator.make_initializer(train_dataset)\n",
    "    valid_initialize_op = iterator.make_initializer(valid_dataset)\n",
    "    \n",
    "    logits = semi_alexnet_v1.semi_alexnet_v1(images, len(LABELS_MAP), True)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        logits=logits, onehot_labels=onehot_labels)\n",
    "\n",
    "    print \"One hot:\", onehot_labels.shape.as_list()\n",
    "    labels = tf.argmax(onehot_labels, axis=1)\n",
    "    predictions = tf.argmax(logits, axis=1)\n",
    "\n",
    "    print labels.shape.as_list()\n",
    "    print predictions.shape.as_list()\n",
    "\n",
    "    accuracy, acc_op = tf.metrics.accuracy(labels=labels, predictions=predictions)\n",
    "\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    tf.summary.scalar(\"accuracy\", acc_op)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512243547\n"
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = \"{}\".format(int(time.time()))\n",
    "print run\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "train_writer = tf.summary.FileWriter(\"./summary/\"+run, graph=graph)\n",
    "\n",
    "with tf.Session(config=config, graph=graph) as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    counter = tqdm_notebook(range(len(train_data)/BATCH_SIZE))\n",
    "    sess.run(train_initialize_op)\n",
    "    while True:\n",
    "        try:\n",
    "            summary, opt, l, a, acc = sess.run([merged_summary, optimizer, loss, accuracy, acc_op])\n",
    "            counter.set_postfix({\n",
    "                \"loss\": \"{:.6}\".format(l),\n",
    "                \"accuracy\": acc\n",
    "            })\n",
    "            train_writer.add_summary(summary, i)\n",
    "            counter.update(1)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print \"Finished training\"\n",
    "\n",
    "    counter = tqdm_notebook(range(len(train_data)/BATCH_SIZE))\n",
    "    summ_acc = 0.\n",
    "    sess.run(valid_initialize_op)\n",
    "    while True:\n",
    "        try:\n",
    "            summary, l, a, acc = sess.run([merged_summary, loss, accuracy, acc_op])\n",
    "            counter.set_postfix({\n",
    "                \"loss\": \"{:.6}\".format(l),\n",
    "                \"accuracy\": acc\n",
    "            })\n",
    "            summ_acc += acc\n",
    "            train_writer.add_summary(summary, i)\n",
    "            counter.update(1)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print \"Finished validation. Average accuracy: {}\".format(summ_acc/(1.*len(valid_data)/BATCH_SIZE))\n",
    "    saver.save(sess, os.path.join(\"model\", run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)/BATCH_SIZE * EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Invalid url!', u'person individual someone somebody mortal soul', u'goldfish Carassius auratus', u'ray', u'bird', u'frog toad toad frog anuran batrachian salientian', u'turtle', u'lizard', u'snake serpent ophidian', u'scorpion', u'tick', u'centipede', u'koala koala bear kangaroo bear native bear Phascolarctos cinereus', u'jellyfish', u'snail', u'lobster', u'isopod', u'whale', u'seal', u'dog domestic dog Canis familiaris', u'fox', u'domestic cat house cat Felis domesticus Felis catus', u'lion king of beasts Panthera leo', u'tiger Panthera tigris', u'bear', u'ladybug ladybeetle lady beetle ladybird ladybird beetle', u'bee', u'ant emmet pismire', u\"dragonfly darning needle devil's darning needle sewing needle snake feeder snake doctor mosquito hawk skeeter hawk\", u'butterfly', u'starfish sea star', u'rabbit coney cony', u'hamster', u'porcupine hedgehog', u'squirrel', u'horse Equus caballus', u'zebra', u'swine', u'hippopotamus hippo river horse Hippopotamus amphibius', u'cattle cows kine oxen Bos taurus', u'sheep', u'antelope', u'camel', u'otter', u'skunk polecat wood pussy', u'armadillo', u'monkey', u'elephant', u'lesser panda red panda panda bear cat cat bear Ailurus fulgens', u'giant panda panda panda bear coon bear Ailuropoda melanoleuca', u'accordion piano accordion squeeze box', u'airplane aeroplane plane', u'ax axe', u\"baby bed baby's bed\", u'backpack back pack knapsack packsack rucksack haversack', u'balance beam beam', u'Band Aid', u'banjo', u'baseball', u'basketball', u'beaker', u'bench', u'bicycle bike wheel cycle', u'binder ring-binder', u'bookcase', u'bow', u'bowl', u'bow tie bow-tie bowtie', u'brassiere bra bandeau', u'bus autobus coach charabanc double-decker jitney motorbus motorcoach omnibus passenger vehicle', u'can opener tin opener', u'car auto automobile machine motorcar', u'cart', u'cello violoncello', u'chain saw chainsaw', u'chair', u'chime bell gong', u'cocktail shaker', u'coffee maker', u'computer keyboard keypad', u'corkscrew bottle screw', u'cornet horn trumpet trump', u'cowboy hat ten-gallon hat', u'cream ointment emollient', u'croquet ball', u'crutch', u'diaper nappy napkin', u'digital clock', u'dishwasher dish washer dishwashing machine', u'display video display', u'drum membranophone tympan', u'dumbbell', u'electric fan blower', u'face powder', u'file file cabinet filing cabinet', u'flute transverse flute', u'French horn horn', u'frying pan frypan skillet', u'golf ball', u'golfcart golf cart', u'guitar', u'hair spray', u'hammer', u'hand blower blow dryer blow drier hair dryer hair drier', u'harmonica mouth organ harp mouth harp', u'harp', u'helmet', u'horizontal bar high bar', u'iPod', u'ladle', u'lamp', u'laptop laptop computer', u'lipstick lip rouge', u'maillot tank suit', u'maraca', u'microphone mike', u'microwave microwave oven', u'milk can', u'miniskirt mini', u'motorcycle bike', u'mouse computer mouse', u'mug', u'nail', u'oboe hautboy hautbois', u'pencil box pencil case', u'pencil sharpener', u'perfume essence', u'piano pianoforte forte-piano', u'ping-pong ball', u'pitcher ewer', u'plastic bag', u'plate rack', u'pot flowerpot', u'power drill', u'printer', u'puck hockey puck', u'punching bag punch bag punching ball punchball', u'purse', u'racket racquet', u'refrigerator icebox', u'remote control remote', u'rubber eraser rubber pencil eraser', u'rugby ball', u'rule ruler', u'saltshaker salt shaker', u'sax saxophone', u'screwdriver', u'ski', u'snowmobile', u'snowplow snowplough', u'soap dispenser', u'soccer ball', u'sofa couch lounge', u'spatula', u'stethoscope', u'stove', u'strainer', u'stretcher', u'sunglasses dark glasses shades', u'swimming trunks bathing trunks', u'syringe', u'table', u'tape player', u'tennis ball', u'toaster', u'train railroad train', u'trombone', u'unicycle monocycle', u'vacuum vacuum cleaner', u'vessel watercraft', u'violin fiddle', u'volleyball', u'waffle iron', u'washer automatic washer washing machine', u'water bottle', u'Windsor tie', u'wine bottle', u'traffic light traffic signal stoplight', u'guacamole', u'ice lolly lolly lollipop popsicle', u'bagel beigel', u'pretzel', u'hamburger beefburger burger', u'hotdog hot dog red hot', u'head cabbage', u'cucumber cuke', u'artichoke globe artichoke', u'bell pepper', u'mushroom', u'apple', u'strawberry', u'orange', u'lemon', u'fig', u'pineapple ananas', u'banana', u'pomegranate', u'pizza pizza pie', u'burrito']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with (open(os.path.join(\"model\", run+\".categories\"), \"w\")) as f:\n",
    "    print [reader.get_desc(w) for w in pd.get_dummies(data.class_id).columns]\n",
    "    f.write(pickle.dumps([reader.get_desc(w) for w in pd.get_dummies(data.class_id).columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reader.CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
